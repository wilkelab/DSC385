{
  "hash": "4b16dfbe79e418f7bfd221686f176fc3",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Dimension reduction 1\"\nauthor: \"Claus O. Wilke\"\nformat: live-html\nengine: knitr\nwebr:\n  render-df: gt-interactive\n---\n\n::: {.cell}\n\n:::\n\n\n\n\n\n## Introduction\n\nIn this worksheet, we will discuss how to perform principal components analysis (PCA).\n\nFirst we need to load the required R packages. Please wait a moment until the live R session is fully set up and all packages are loaded.\n\n\n\n\n::: {.cell edit='false'}\n```{webr}\n#| warning: false\n#| edit: false\nlibrary(tidyverse)\nlibrary(broom)\n```\n:::\n\n\n\n\nNext we set up the data.\n\n\n\n\n::: {.cell edit='false'}\n```{webr}\n#| edit: false\n#| warning: false\nblue_jays <- read_csv(\"https://wilkelab.org/DSC385/datasets/blue_jays.csv\")\n```\n:::\n\n\n\n\nWe will be working with the dataset `blue_jays`. It contains various measurements taken on blue jay birds.\n\n\n\n\n::: {.cell edit='false'}\n```{webr}\n#| edit: false\nblue_jays\n```\n:::\n\n\n\n\n## Performing a PCA\n\nWe can perform a PCA with the function `prcomp()`. However, we first need to prepare the data. PCA can only take numeric columns, and it is best to scale all variables to zero mean and unit variance. \n\nWe can select all numeric columns in a dataset with `select(where(is.numeric))` and we can scale an entire dataset consisting of only numeric columns with `scale()`. Try this on the `blue_jays` dataset. Modify the dataset so it is entirely numeric and properly scaled.\n\n\n\n\n::: {.cell exercise='scaling'}\n```{webr}\n#| exercise: scaling\nblue_jays |>\n  ___\n```\n:::\n\n\n\n\n::: { .hint exercise=\"scaling\" }\n::: { .callout-tip title=\"Hint\" collapse=\"false\"}\n```r\nblue_jays |>\n  select(where(is.numeric)) |>\n  ___\n```\n:::\n:::\n\n::: { .solution exercise=\"scaling\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\nblue_jays |>\n  select(where(is.numeric)) |>\n  scale()\n```\n:::\n:::\n\nNext run `prcomp()` on this modified dataset.\n\n\n\n\n::: {.cell exercise='pca'}\n```{webr}\n#| exercise: pca\n\n```\n:::\n\n\n\n\n::: { .hint exercise=\"pca\" }\n::: { .callout-tip title=\"Hint\" collapse=\"false\"}\n```r\nblue_jays |>\n  select(where(is.numeric)) |>\n  scale() |>\n  ___\n```\n:::\n:::\n\n::: { .solution exercise=\"pca\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\nblue_jays |>\n  select(where(is.numeric)) |>\n  scale() |>\n  prcomp()\n```\n:::\n:::\n\nIn practice, we store the output from `prcomp()` in a variable for subsequent downstream manipulations:\n\n\n\n\n::: {.cell edit='false'}\n```{webr}\n#| edit: false\npca_fit <- blue_jays |>\n  select(where(is.numeric)) |>\n  scale() |>\n  prcomp()\n```\n:::\n\n\n\n\nThen we can extract useful data from this model fit object by running various functions from the **broom** package on it. For example, the `tidy()` function extracts model parameters in a tidy format. It takes an argument `matrix` that can take the values `\"scores\"`, `\"rotation\"`, and `\"eigenvalues\"`. See what these different options do.\n\n\n\n\n::: {.cell exercise='pca-tidy'}\n```{webr}\n#| exercise: pca-tidy\npca_fit |>\n  tidy(matrix = ___)\n```\n:::\n\n\n\n\n::: { .solution exercise=\"pca-tidy\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\npca_fit |>\n  tidy(matrix = \"scores\")\n\npca_fit |>\n  tidy(matrix = \"rotation\")\n\npca_fit |>\n  tidy(matrix = \"eigenvalues\")\n```\n:::\n:::\n\nWe can also add the original dataset back into the PCA coordinates via the `augment()` function. This is helpful for example when we want to plot values from the original dataset (such as some of the categorical variables removed at the first step of the analysis) in the transformed coordinate system. Try out how `augment()` works.\n\n\n\n\n::: {.cell exercise='pca-augment'}\n```{webr}\n#| exercise: pca-augment\npca_fit |>\n  ___\n```\n:::\n\n\n\n\n::: { .hint exercise=\"pca-augment\" }\n::: { .callout-tip title=\"Hint\" collapse=\"false\"}\n```r\npca_fit |>\n  augment(___)\n```\n:::\n:::\n\n::: { .solution exercise=\"pca-augment\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\npca_fit |>\n  augment(blue_jays)\n```\n:::\n:::\n\n## Making a PCA plot\n\nWhen plotting the results from a PCA, we usually make three separate plots: (i) we plot the individual data points in PC coordinates, (ii) we plot the rotation matrix, and (iii) we plot the variance explained by each components. Let's discuss each of these in turn.\n\n### Plotting individual data points in PC coordinates\n\nIn the previous subsection, we used `augment()` to add the original dataset back into the PCA coordinates. The result from this computation can be used directly in ggplot. Try this out by plotting PC 2 versus PC 1 and coloring by the sex of the birds. Remember: The columns containing PC coordinates are called `.fittedPC1`, `.fittedPC2`, etc.\n\n\n\n\n::: {.cell exercise='pca-scatter'}\n```{webr}\n#| exercise: pca-scatter\npca_fit |>\n  augment(blue_jays) |>\n  ggplot(___) +\n  ___\n```\n:::\n\n\n\n\n::: { .hint exercise=\"pca-scatter\" }\n::: { .callout-tip title=\"Hint\" collapse=\"false\"}\n```r\npca_fit |>\n  augment(blue_jays) |>\n  ggplot(aes(.fittedPC1, .fittedPC2, color = sex)) +\n  ___\n```\n:::\n:::\n\n::: { .solution exercise=\"pca-scatter\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\npca_fit |>\n  augment(blue_jays) |>\n  ggplot(aes(.fittedPC1, .fittedPC2, color = sex)) +\n  geom_point() +\n  coord_fixed()\n```\n:::\n:::\n\nTry also plotting other PC coordinates, e.g. PC 3 vs PC 2 or PC 3 vs PC 1.\n\n### Plotting the rotation matrix\n\nTo plot the rotation matrix we require a bit of boiler-plate code. It is always the same, so it's fine to copy-and-paste when needed. This is the baseline for a rotation-matrix plot:\n\n```r\n# define an arrow style\narrow_style <- arrow(\n  angle = 20, length = grid::unit(8, \"pt\"),\n  ends = \"first\", type = \"closed\"\n)\n\npca_fit |>\n  tidy(matrix = \"rotation\") |>  # extract rotation matrix\n  pivot_wider(\n    names_from = \"PC\", values_from = \"value\",\n    names_prefix = \"PC\"\n  ) |>\n  ggplot(aes(PC1, PC2)) +\n  geom_segment(\n    xend = 0, yend = 0,\n    arrow = arrow_style\n  ) +\n  geom_text(aes(label = column)) +\n  coord_fixed(\n    # you will generally have to set the limits appropriately\n    xlim = ___,\n    ylim = ___\n  )\n```\n\nUse the above code to plot the rotation matrix for the blue jays PCA analysis. Make two customizations: 1. Change the x and y limits to appropriate values. Use `hjust` and/or `vjust` in `geom_text()` to aligne the text labels appropriately.\n\n\n\n\n::: {.cell exercise='rotation-plot'}\n```{webr}\n#| exercise: rotation-plot\n\n```\n:::\n\n\n\n\n::: { .solution exercise=\"rotation-plot\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\n# define an arrow style\narrow_style <- arrow(\n  angle = 20, length = grid::unit(8, \"pt\"),\n  ends = \"first\", type = \"closed\"\n)\n\npca_fit |>\n  tidy(matrix = \"rotation\") |>  # extract rotation matrix\n  pivot_wider(\n    names_from = \"PC\", values_from = \"value\",\n    names_prefix = \"PC\"\n  ) |>\n  ggplot(aes(PC1, PC2)) +\n  geom_segment(\n    xend = 0, yend = 0,\n    arrow = arrow_style\n  ) +\n  geom_text(aes(label = column), hjust = 1) +\n  coord_fixed(\n    xlim = c(-1.7, .5),\n    ylim = c(-1, 1)\n  )\n```\n:::\n:::\n\n\nNow do the same for PC 2 versus PC 3. (Hint: This means putting PC 3 on the x axis.)\n\n\n\n\n::: {.cell exercise='rotation-plot2'}\n```{webr}\n#| exercise: rotation-plot2\n\n```\n:::\n\n\n\n\n::: { .solution exercise=\"rotation-plot2\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\n# define an arrow style\narrow_style <- arrow(\n  angle = 20, length = grid::unit(8, \"pt\"),\n  ends = \"first\", type = \"closed\"\n)\n\npca_fit |>\n  tidy(matrix = \"rotation\") |>  # extract rotation matrix\n  pivot_wider(\n    names_from = \"PC\", values_from = \"value\",\n    names_prefix = \"PC\"\n  ) |>\n  ggplot(aes(PC3, PC2)) +\n  geom_segment(\n    xend = 0, yend = 0,\n    arrow = arrow_style\n  ) +\n  geom_text(aes(label = column), hjust = c(1, 0, 1, 1, 1, 1)) +\n  coord_fixed(\n    xlim = c(-1.3, 1.8),\n    ylim = c(-1, .8)\n  )\n```\n:::\n:::\n\n\n### Plotting the eigenvalues (variance explained)\n\nTo plot the variance explained, we extract the eigenvalues with the function `tidy()`, as discussed above. As a reminder, do this one more time and inspect the structure of the output.\n\n\n\n\n::: {.cell exercise='pca-eigenvalues'}\n```{webr}\n#| exercise: pca-eigenvalues\n\n```\n:::\n\n\n\n\n::: { .hint exercise=\"pca-eigenvalues\" }\n::: { .callout-tip title=\"Hint\" collapse=\"false\"}\n```r\npca_fit |>\n  tidy(___)\n```\n:::\n:::\n\n::: { .solution exercise=\"pca-eigenvalues\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\npca_fit |>\n  tidy(matrix = \"eigenvalues\")\n```\n:::\n:::\n\nNow make a bar plot of the percent variance explained (column `percent`) by each PC.\n\n\n\n\n::: {.cell exercise='pca-eigenvalues-plot'}\n```{webr}\n#| exercise: pca-eigenvalues-plot\n\n```\n:::\n\n\n\n\n::: { .hint exercise=\"pca-eigenvalues-plot\" }\n::: { .callout-tip title=\"Hint\" collapse=\"false\"}\n```r\npca_fit |>\n  tidy(matrix = \"eigenvalues\") |>\n  ggplot(___) + \n  ___\n```\n:::\n:::\n\n::: { .solution exercise=\"pca-eigenvalues-plot\" }\n::: { .callout-tip title=\"Solution\" collapse=\"false\"}\n```r\npca_fit |>\n  tidy(matrix = \"eigenvalues\") |>\n  ggplot(aes(PC, percent)) +\n  geom_col() +\n  scale_x_continuous(breaks = 1:6) +\n  scale_y_continuous(labels = scales::label_percent())\n```\n:::\n:::\n",
    "supporting": [
      "dimension-reduction-1_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}